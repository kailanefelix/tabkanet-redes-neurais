{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-24 20:02:15,093 - root - INFO - Device: cpu\n",
      "Epoch 1/10: 100%|██████████| 13/13 [00:03<00:00,  3.50it/s, loss=0.284]\n",
      "Epochs:  10%|█         | 1/10 [01:36<14:26, 96.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 0.2312, Val Loss: 0.1160,Val AUC:0.9980, Val Metric: 0.9863, Test Metric: 0.9405 , Test AUC: 0.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 13/13 [00:02<00:00,  4.39it/s, loss=0.134]\n",
      "Epochs:  20%|██        | 2/10 [03:25<13:51, 103.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 0.2381, Val Loss: 0.0800,Val AUC:0.9993, Val Metric: 0.9860, Test Metric: 0.9400 , Test AUC: 0.9961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 13/13 [00:02<00:00,  4.46it/s, loss=0.0934]\n",
      "Epochs:  30%|███       | 3/10 [05:17<12:33, 107.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Train Loss: 0.1624, Val Loss: 0.0669,Val AUC:0.9987, Val Metric: 0.9723, Test Metric: 0.9522 , Test AUC: 0.9934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 13/13 [00:03<00:00,  4.15it/s, loss=0.0757]\n",
      "Epochs:  40%|████      | 4/10 [07:09<10:55, 109.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Train Loss: 0.1622, Val Loss: 0.0731,Val AUC:0.9987, Val Metric: 0.9723, Test Metric: 0.9288 , Test AUC: 0.9950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 13/13 [00:03<00:00,  3.87it/s, loss=0.0616]\n",
      "Epochs:  50%|█████     | 5/10 [09:00<09:10, 110.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Train Loss: 0.1048, Val Loss: 0.0571,Val AUC:0.9987, Val Metric: 0.9723, Test Metric: 0.9522 , Test AUC: 0.9956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 13/13 [00:03<00:00,  4.03it/s, loss=0.054]\n",
      "Epochs:  60%|██████    | 6/10 [10:38<07:03, 105.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, Train Loss: 0.0851, Val Loss: 0.0600,Val AUC:0.9993, Val Metric: 0.9863, Test Metric: 0.9412 , Test AUC: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 13/13 [00:03<00:00,  4.05it/s, loss=0.0581]\n",
      "Epochs:  70%|███████   | 7/10 [12:27<05:20, 106.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, Train Loss: 0.1780, Val Loss: 0.0426,Val AUC:0.9993, Val Metric: 0.9723, Test Metric: 0.9283 , Test AUC: 0.9912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 13/13 [00:02<00:00,  4.39it/s, loss=0.0412]\n",
      "Epochs:  70%|███████   | 7/10 [14:14<06:06, 122.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Train Loss: 0.1508, Val Loss: 0.0644,Val AUC:0.9993, Val Metric: 0.9863, Test Metric: 0.9293 , Test AUC: 0.9901\n",
      "Early stopping\n",
      "FINISHED TRAINING, BEST VAL AUC:0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from tabkanet.models import TabMLPNet\n",
    "from tabkanet.tools import seed_everything, get_dataset, get_data_loader, train\n",
    "from tabkanet.metrics import f1_score_macro\n",
    "\n",
    "# Fixar a semente para reprodutibilidade\n",
    "seed = 0\n",
    "seed_everything(seed)\n",
    "\n",
    "def load_breast_cancer_data():\n",
    "    data = load_breast_cancer()\n",
    "    df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "    df[\"target\"] = data.target\n",
    "    \n",
    "    # Normalizar os dados\n",
    "    scaler = StandardScaler()\n",
    "    df[data.feature_names] = scaler.fit_transform(df[data.feature_names])\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        df.drop(columns=[\"target\"]), df[\"target\"], test_size=0.3, random_state=seed\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=seed\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "# Função para calcular os bins\n",
    "def get_quantile_bins(x_cont, n_bins=4):\n",
    "    feature_dim = x_cont.shape[1]\n",
    "    bins = torch.zeros(feature_dim, n_bins + 1)\n",
    "    for i in range(feature_dim):\n",
    "        # Converta a coluna específica para tensor e depois calcule os quantis\n",
    "        quantiles = torch.quantile(torch.tensor(x_cont.iloc[:, i].values, dtype=torch.float32), torch.linspace(0, 1, n_bins + 1))\n",
    "        bins[i] = quantiles\n",
    "    return bins\n",
    "\n",
    "\n",
    "# Carregar o dataset Breast Cancer\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = load_breast_cancer_data()\n",
    "\n",
    "# Definir features\n",
    "continuous_features = list(X_train.columns)\n",
    "categorical_features = []\n",
    "target_name = \"target\"\n",
    "task = \"classification\"\n",
    "\n",
    "# Criar datasets\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "df_val = pd.concat([X_val, y_val], axis=1)\n",
    "df_test = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "dataset_train, dataset_val, dataset_test = get_dataset(\n",
    "    df_train, df_val, df_test, target_name, task, categorical_features, continuous_features\n",
    ")\n",
    "\n",
    "dataloader_train, dataloader_val, dataloader_test = get_data_loader(\n",
    "    dataset_train, dataset_val, dataset_test, train_batch_size=32, inference_batch_size=32\n",
    ")\n",
    "\n",
    "# Calcular bins\n",
    "bins = get_quantile_bins(X_train)\n",
    "\n",
    "# Definir o modelo\n",
    "model = TabMLPNet(\n",
    "    output_dim=2,  # 2 classes (binário)\n",
    "    vocabulary={},\n",
    "    num_continuous_features=len(continuous_features),\n",
    "    embedding_dim=16, \n",
    "    mlp_hidden_dims=[32],\n",
    "    activation=\"relu\",\n",
    "    ffn_dropout_rate=0.1,\n",
    "    nhead=8,\n",
    "    num_layers=3,\n",
    "    dim_feedforward=128,\n",
    "    attn_dropout_rate=0.1,\n",
    "    learninable_noise=True,\n",
    "    bins=bins\n",
    ")\n",
    "\n",
    "# Definir otimizador e loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Treinar o modelo\n",
    "train_history, val_history, test_history = train(\n",
    "    model, epochs=10, task=task, train_loader=dataloader_train, val_loader=dataloader_val,\n",
    "    test_loader=dataloader_test, optimizer=optimizer, criterion=criterion,\n",
    "    custom_metric=f1_score_macro, maximize=False, early_stopping_patience=5, gpu_num=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
